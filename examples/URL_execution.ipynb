{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dc7f347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>space</th>\n",
       "      <th>proposal_id</th>\n",
       "      <th>title</th>\n",
       "      <th>end_iso</th>\n",
       "      <th>num_voters</th>\n",
       "      <th>vp_min</th>\n",
       "      <th>vp_25%</th>\n",
       "      <th>vp_median</th>\n",
       "      <th>vp_75%</th>\n",
       "      <th>vp_max</th>\n",
       "      <th>vp_mean</th>\n",
       "      <th>vp_std</th>\n",
       "      <th>sp_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>arbitrumfoundation.eth</td>\n",
       "      <td>0x070a960cf0d8824badc07f0478040a16e92959c71b6e...</td>\n",
       "      <td>Curve STIP Proposal - Round 1</td>\n",
       "      <td>2023-10-13T02:00:00+00:00</td>\n",
       "      <td>21353</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.590204</td>\n",
       "      <td>24.725582</td>\n",
       "      <td>2.755511e+07</td>\n",
       "      <td>6384.509831</td>\n",
       "      <td>285644.558801</td>\n",
       "      <td>1.363284e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      space  \\\n",
       "986  arbitrumfoundation.eth   \n",
       "\n",
       "                                           proposal_id  \\\n",
       "986  0x070a960cf0d8824badc07f0478040a16e92959c71b6e...   \n",
       "\n",
       "                             title                    end_iso  num_voters  \\\n",
       "986  Curve STIP Proposal - Round 1  2023-10-13T02:00:00+00:00       21353   \n",
       "\n",
       "           vp_min  vp_25%  vp_median     vp_75%        vp_max      vp_mean  \\\n",
       "986  1.000000e-18     1.1   3.590204  24.725582  2.755511e+07  6384.509831   \n",
       "\n",
       "            vp_std        sp_sum  \n",
       "986  285644.558801  1.363284e+08  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, re, subprocess, sys, time, os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Dict, Any, Tuple, Set\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm  # pip install tqdm\n",
    "\n",
    "# ========= Config =========\n",
    "REPO_ROOT = Path(\"/Users/chunghyunhan/Projects/agentics\").resolve()\n",
    "CSV_PATH = REPO_ROOT / \"dao_finished_proposals_stats.csv\"\n",
    "SCRIPT = REPO_ROOT / \"examples\" / \"agentics_proposal_decision.py\"\n",
    "\n",
    "DEFAULT_RUN_DIR = REPO_ROOT / \"Decision_runs\"\n",
    "OUTPUT_DIR = REPO_ROOT / \"Decision_runs_result_saving\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Performance / robustness knobs\n",
    "SUBPROC_TIMEOUT_SEC = 600           # kill if a single run hangs > 10 minutes\n",
    "SLEEP_BETWEEN_RUNS_SEC = 0.5        # spacing to respect MCP/LLM rate limits\n",
    "CHECKPOINT_EVERY = 25               # write a checkpoint parquet every N runs\n",
    "RESUME_IF_EXISTS = True             # skip proposals that already have saved_json\n",
    "FAIL_STOP_AFTER = None              # e.g., set to 10 to abort after 10 failures\n",
    "\n",
    "# ========= Load =========\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df = df[986:987]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d05192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633795b1ca0347729d09015fa6f166dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Snapshot proposals:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[986/0] arbitrumfoundation.eth :: 0x070a960cf0d8824badc07f0478040a16e92959c71b6e1ca49e67d96714dabc42 -> https://snapshot.org/#/arbitrumfoundation.eth/proposal/0x070a960cf0d8824badc07f0478040a16e92959c71b6e1ca49e67d96714dabc42\n",
      "Done. 1 runs | ok=1 | skip=0 | timeout=0 | fail=0 | elapsed=147.9s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Basic column validation (defensive)\n",
    "for col in (\"space\", \"proposal_id\"):\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column in CSV: {col!r}\")\n",
    "\n",
    "# ========= Helpers =========\n",
    "def snapshot_url(space: str, proposal_id: str) -> str:\n",
    "    return f\"https://snapshot.org/#/{space}/proposal/{proposal_id}\"\n",
    "\n",
    "_SANITIZE = re.compile(r\"[^A-Za-z0-9._-]\")\n",
    "\n",
    "def sanitize(s: str) -> str:\n",
    "    return _SANITIZE.sub(\"_\", str(s))\n",
    "\n",
    "def derive_filename(space: str, index: int, proposal_id: str) -> Path:\n",
    "    \"\"\"Legacy canonical name (kept for backward-compat).\"\"\"\n",
    "    safe_space = sanitize(space)\n",
    "    safe_pid = sanitize(proposal_id)\n",
    "    return OUTPUT_DIR / f\"{safe_space}_{index:04d}_{safe_pid}.json\"\n",
    "\n",
    "def has_saved(space: str, proposal_id: str) -> bool:\n",
    "    \"\"\"\n",
    "    Index-independent existence check.\n",
    "    We glob for any file like {space}_*_{proposal_id}.json\n",
    "    so reordering/slicing of CSV won't break resume.\n",
    "    \"\"\"\n",
    "    safe_space = sanitize(space)\n",
    "    safe_pid = sanitize(proposal_id)\n",
    "    pattern = f\"{safe_space}_*_{safe_pid}.json\"\n",
    "    return any(OUTPUT_DIR.glob(pattern))\n",
    "\n",
    "def run_decision(url: str) -> subprocess.CompletedProcess:\n",
    "    \"\"\"Run the interactive script once with canned stdin.\"\"\"\n",
    "    canned_input = f\"{url}\\n\"   # Snapshot Proposal URL>\n",
    "    canned_input += \"n\\n\"       # reuse focus areas? -> no\n",
    "    canned_input += \"\\n\"        # custom focus (blank)\n",
    "    env = os.environ.copy()\n",
    "    src_path = str(REPO_ROOT / \"src\")\n",
    "    existing = env.get(\"PYTHONPATH\")\n",
    "    env[\"PYTHONPATH\"] = src_path if not existing else f\"{src_path}:{existing}\"\n",
    "    return subprocess.run(\n",
    "        [sys.executable, str(SCRIPT)],\n",
    "        input=canned_input,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        cwd=REPO_ROOT,\n",
    "        env=env,\n",
    "        check=False,            # don't raise; we inspect returncode\n",
    "        timeout=SUBPROC_TIMEOUT_SEC,\n",
    "    )\n",
    "\n",
    "_SAVED_REGEX = re.compile(r\"Saved:\\s*(.*Decision_runs/decision_[0-9T:-]+\\.json)\")\n",
    "\n",
    "def extract_saved_path(stdout: str) -> Optional[Path]:\n",
    "    m = _SAVED_REGEX.search(stdout or \"\")\n",
    "    return Path(m.group(1)).resolve() if m else None\n",
    "\n",
    "def summarize_status(rec: Dict[str, Any]) -> str:\n",
    "    if rec.get(\"skipped\"):\n",
    "        return \"skip\"\n",
    "    rc = rec.get(\"returncode\")\n",
    "    if rc == 0 and rec.get(\"saved_json\"):\n",
    "        return \"ok\"\n",
    "    if rec.get(\"timeout\"):\n",
    "        return \"timeout\"\n",
    "    return f\"fail(rc={rc})\"\n",
    "\n",
    "# ========= Pre-compute already-done set (index-independent) =========\n",
    "if RESUME_IF_EXISTS:\n",
    "    done_pairs: Set[Tuple[str, str]] = set()\n",
    "    # Parse existing files in OUTPUT_DIR\n",
    "    for p in OUTPUT_DIR.glob(\"*.json\"):\n",
    "        name = p.name  # e.g., aavedao.eth_0001_0xabcde....json\n",
    "        try:\n",
    "            # split by last underscore to get proposal_id; the rest is space + index\n",
    "            # safer: split from right at most once\n",
    "            head, _, tail = name.rpartition(\"_\")\n",
    "            pid = tail[:-5]  # strip \".json\"\n",
    "            space = head.split(\"_\", 1)[0]  # before first underscore is space (sanitized)\n",
    "            done_pairs.add((space, pid))\n",
    "        except Exception:\n",
    "            # if parsing fails, ignore (still covered by per-iteration has_saved)\n",
    "            pass\n",
    "else:\n",
    "    done_pairs = set()\n",
    "\n",
    "# Filter DF to remaining work (so we don't even iterate finished ones)\n",
    "if RESUME_IF_EXISTS and len(done_pairs) > 0:\n",
    "    # Compare with sanitized names to match file naming\n",
    "    df[\"_space_key\"] = df[\"space\"].map(sanitize)\n",
    "    df[\"_pid_key\"] = df[\"proposal_id\"].map(sanitize)\n",
    "    mask = ~df.apply(lambda r: (r[\"_space_key\"], r[\"_pid_key\"]) in done_pairs, axis=1)\n",
    "    df_remaining = df[mask].drop(columns=[\"_space_key\", \"_pid_key\"])\n",
    "else:\n",
    "    df_remaining = df\n",
    "\n",
    "print(f\"Total rows: {len(df)} | Remaining after resume filter: {len(df_remaining)}\")\n",
    "\n",
    "# ========= Main =========\n",
    "results = []\n",
    "fail_count = 0\n",
    "start_all = time.time()\n",
    "\n",
    "progress = tqdm(\n",
    "    df_remaining.itertuples(index=True, name=\"Proposal\"),\n",
    "    total=len(df_remaining),\n",
    "    desc=\"Processing Snapshot proposals\",\n",
    "    dynamic_ncols=True,\n",
    "    leave=True,\n",
    ")\n",
    "\n",
    "for row in progress:\n",
    "    idx = int(row.Index)\n",
    "    space = str(row.space)\n",
    "    pid = str(row.proposal_id)\n",
    "    url = snapshot_url(space, pid)\n",
    "\n",
    "    # Index-independent skip (fast path)\n",
    "    if RESUME_IF_EXISTS and has_saved(space, pid):\n",
    "        rec = {\n",
    "            \"index\": idx,\n",
    "            \"space\": space,\n",
    "            \"proposal_id\": pid,\n",
    "            \"snapshot_url\": url,\n",
    "            \"returncode\": 0,\n",
    "            \"stdout\": \"\",\n",
    "            \"stderr\": \"\",\n",
    "            \"saved_json\": str(next(OUTPUT_DIR.glob(f\"{sanitize(space)}_*_{sanitize(pid)}.json\"))),\n",
    "            \"skipped\": True,\n",
    "            \"timeout\": False,\n",
    "            \"started_at\": None,\n",
    "            \"ended_at\": None,\n",
    "            \"elapsed_sec\": 0.0,\n",
    "        }\n",
    "        results.append(rec)\n",
    "        progress.set_postfix({\"status\": \"skip\", \"space\": space, \"id\": pid[:8]})\n",
    "        continue\n",
    "\n",
    "    # For new runs, also compute canonical target (kept for continuity)\n",
    "    target_path = derive_filename(space, idx, pid)\n",
    "\n",
    "    # Show what's being processed right now\n",
    "    progress.set_postfix({\"status\": \"run\", \"space\": space, \"id\": pid[:8]})\n",
    "    tqdm.write(f\"[{idx}] {space} :: {pid} -> {url}\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    started_at = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    proc = None\n",
    "    timeout_hit = False\n",
    "    try:\n",
    "        proc = run_decision(url)\n",
    "    except subprocess.TimeoutExpired as te:\n",
    "        timeout_hit = True\n",
    "        proc = te\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    ended_at = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    # Try to pull the saved path from stdout\n",
    "    saved_path = None\n",
    "    stdout_text = getattr(proc, \"stdout\", \"\")\n",
    "    stderr_text = getattr(proc, \"stderr\", \"\")\n",
    "    saved_path = extract_saved_path(stdout_text or \"\")\n",
    "\n",
    "    renamed_path = None\n",
    "    if saved_path and saved_path.exists():\n",
    "        # Move into our OUTPUT_DIR with canonical name\n",
    "        target_path.write_bytes(saved_path.read_bytes())\n",
    "        try:\n",
    "            saved_path.unlink()\n",
    "        except Exception:\n",
    "            pass\n",
    "        renamed_path = target_path\n",
    "\n",
    "    rec = {\n",
    "        \"index\": idx,\n",
    "        \"space\": space,\n",
    "        \"proposal_id\": pid,\n",
    "        \"snapshot_url\": url,\n",
    "        \"returncode\": getattr(proc, \"returncode\", None),\n",
    "        \"stdout\": stdout_text,\n",
    "        \"stderr\": stderr_text,\n",
    "        \"saved_json\": str(renamed_path) if renamed_path else None,\n",
    "        \"skipped\": False,\n",
    "        \"timeout\": timeout_hit,\n",
    "        \"started_at\": started_at,\n",
    "        \"ended_at\": ended_at,\n",
    "        \"elapsed_sec\": round(elapsed, 3),\n",
    "    }\n",
    "    results.append(rec)\n",
    "\n",
    "    status = summarize_status(rec)\n",
    "    progress.set_postfix({\"status\": status, \"t\": f\"{elapsed:.1f}s\", \"space\": space, \"id\": pid[:8]})\n",
    "\n",
    "    if status.startswith(\"fail\"):\n",
    "        fail_count += 1\n",
    "        tqdm.write(f\"  -> FAIL ({status}). See stderr below:\")\n",
    "        if stderr_text:\n",
    "            head = \"\\n\".join(stderr_text.splitlines()[:12])\n",
    "            tqdm.write(head)\n",
    "        fail_log = OUTPUT_DIR / f\"fail_{idx:04d}_{sanitize(space)}_{sanitize(pid)[:8]}.log\"\n",
    "        try:\n",
    "            fail_log.write_text(\n",
    "                f\"URL: {url}\\nReturnCode: {rec['returncode']}\\nTimeout: {timeout_hit}\\n\"\n",
    "                f\"--- STDOUT ---\\n{stdout_text}\\n\\n--- STDERR ---\\n{stderr_text}\\n\"\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "        if FAIL_STOP_AFTER and fail_count >= FAIL_STOP_AFTER:\n",
    "            tqdm.write(f\"Aborting after {fail_count} failures (FAIL_STOP_AFTER).\")\n",
    "            break\n",
    "\n",
    "    # checkpoint save\n",
    "    if len(results) % CHECKPOINT_EVERY == 0:\n",
    "        ckpt = pd.DataFrame(results)\n",
    "        ckpt.to_parquet(OUTPUT_DIR / \"run_log_ckpt.parquet\", index=False)\n",
    "        tqdm.write(f\"[checkpoint] wrote {len(results)} records\")\n",
    "\n",
    "    # spacing to be gentle with MCP/LLM rate limits\n",
    "    time.sleep(SLEEP_BETWEEN_RUNS_SEC)\n",
    "\n",
    "# Final save\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_parquet(OUTPUT_DIR / \"run_log.parquet\", index=False)\n",
    "\n",
    "tqdm.write(\n",
    "    f\"Done. {len(results)} processed | \"\n",
    "    f\"ok={sum(1 for r in results if summarize_status(r)=='ok')} | \"\n",
    "    f\"skip={sum(1 for r in results if r.get('skipped'))} | \"\n",
    "    f\"timeout={sum(1 for r in results if r.get('timeout'))} | \"\n",
    "    f\"fail={sum(1 for r in results if summarize_status(r).startswith('fail'))}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
