{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4102f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Snapshot 프로포절 수집 시작...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Spaces: 100%|██████████| 10/10 [01:30<00:00,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 완료!\n",
      " - Target_proposals/summary_with_discussion_by_space.csv\n",
      " - Target_proposals/<space>_with_discussion.csv (per space)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from tqdm import tqdm   # 🔹 tqdm 추가\n",
    "\n",
    "# ---------- 기본 설정 ----------\n",
    "SNAPSHOT_API = \"https://hub.snapshot.org/graphql\"\n",
    "TIMEOUT = 30\n",
    "BASE_SLEEP  = 0.6\n",
    "MAX_RETRIES = 5\n",
    "BACKOFF_BASE = 1.7\n",
    "JITTER = (0.1, 0.35)\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"target-proposals/0.1\"})\n",
    "\n",
    "# ---------- 유틸 ----------\n",
    "def _sleep():\n",
    "    time.sleep(BASE_SLEEP + random.uniform(*JITTER))\n",
    "\n",
    "def _now_ts() -> int:\n",
    "    return int(datetime.now(timezone.utc).timestamp())\n",
    "\n",
    "def _ts_to_iso(ts: int) -> str:\n",
    "    return datetime.fromtimestamp(int(ts), tz=timezone.utc).isoformat()\n",
    "\n",
    "# ---------- Snapshot GraphQL ----------\n",
    "PROPOSALS_Q = \"\"\"\n",
    "query($space: String!, $first: Int!, $skip: Int!) {\n",
    "  proposals(\n",
    "    first: $first\n",
    "    skip: $skip\n",
    "    where: { space_in: [$space] }\n",
    "    orderBy: \"created\"\n",
    "    orderDirection: desc\n",
    "  ) {\n",
    "    id\n",
    "    title\n",
    "    author\n",
    "    body\n",
    "    discussion\n",
    "    start\n",
    "    end\n",
    "    state\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def gql(query: str, variables: Optional[dict] = None) -> dict:\n",
    "    retries = 0\n",
    "    while True:\n",
    "        _sleep()\n",
    "        try:\n",
    "            r = session.post(SNAPSHOT_API, json={\"query\": query, \"variables\": variables or {}}, timeout=TIMEOUT)\n",
    "        except requests.RequestException:\n",
    "            if retries < MAX_RETRIES:\n",
    "                delay = (BACKOFF_BASE ** retries) + random.uniform(*JITTER)\n",
    "                time.sleep(delay)\n",
    "                retries += 1\n",
    "                continue\n",
    "            raise\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        if r.status_code in (429, 502, 503, 504) and retries < MAX_RETRIES:\n",
    "            ra = r.headers.get(\"Retry-After\")\n",
    "            delay = float(ra) if (ra and ra.isdigit()) else (BACKOFF_BASE ** retries)\n",
    "            time.sleep(delay + random.uniform(*JITTER))\n",
    "            retries += 1\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "\n",
    "def fetch_all_proposals(space: str, batch: int = 100) -> List[dict]:\n",
    "    out, skip = [], 0\n",
    "    while True:\n",
    "        data = gql(PROPOSALS_Q, {\"space\": space, \"first\": batch, \"skip\": skip})\n",
    "        if not data or \"data\" not in data:\n",
    "            break\n",
    "        chunk = data[\"data\"].get(\"proposals\", [])\n",
    "        if not chunk:\n",
    "            break\n",
    "        out.extend(chunk)\n",
    "        if len(chunk) < batch:\n",
    "            break\n",
    "        skip += batch\n",
    "    return out\n",
    "\n",
    "def finished_only(proposals: List[dict]) -> List[dict]:\n",
    "    nt = _now_ts()\n",
    "    return [p for p in proposals if p.get(\"state\") == \"closed\" and int(p.get(\"end\") or 0) <= nt]\n",
    "\n",
    "def with_discussion_only(proposals: List[dict]) -> List[dict]:\n",
    "    \"\"\"Snapshot의 discussion 필드가 비어있지 않은 것만\"\"\"\n",
    "    return [p for p in proposals if (p.get(\"discussion\") or \"\").strip()]\n",
    "\n",
    "# ---------- 실행 파트 ----------\n",
    "SPACES = [\n",
    "    \"aavedao.eth\",\n",
    "    \"arbitrumfoundation.eth\",\n",
    "    \"snapshot.dcl.eth\",\n",
    "    \"balancer.eth\",\n",
    "    \"cvx.eth\",\n",
    "    \"1inch.eth\",\n",
    "    \"aurafinance.eth\",\n",
    "    \"lido-snapshot.eth\",\n",
    "    \"uniswapgovernance.eth\",\n",
    "    \"metislayer2.eth\",\n",
    "]\n",
    "\n",
    "os.makedirs(\"Target_proposals\", exist_ok=True)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "print(\"🚀 Snapshot 프로포절 수집 시작...\\n\")\n",
    "\n",
    "# tqdm으로 프로세스 진행률 표시\n",
    "for space in tqdm(SPACES, desc=\"Processing Spaces\"):\n",
    "    # 1) 해당 space의 전체 프로포절 가져오기\n",
    "    all_props = fetch_all_proposals(space)\n",
    "    \n",
    "    # 2) 종료(closed) 상태만 남기기\n",
    "    finished_props = finished_only(all_props)\n",
    "    \n",
    "    # 3) discussion 필드가 있는 프로포절만 남기기\n",
    "    discussion_props = with_discussion_only(finished_props)\n",
    "\n",
    "    # 4) space별 개별 CSV 저장\n",
    "    df = pd.DataFrame([{\n",
    "        \"space\": space,\n",
    "        \"id\": p.get(\"id\"),\n",
    "        \"title\": p.get(\"title\"),\n",
    "        \"author\": p.get(\"author\"),\n",
    "        \"discussion\": p.get(\"discussion\"),\n",
    "        \"start\": int(p.get(\"start\") or 0),\n",
    "        \"end\": int(p.get(\"end\") or 0),\n",
    "        \"end_iso\": _ts_to_iso(p.get(\"end\") or 0),\n",
    "        \"state\": p.get(\"state\"),\n",
    "    } for p in discussion_props])\n",
    "    df.to_csv(f\"Target_proposals/{space}_with_discussion.csv\", index=False)\n",
    "\n",
    "    # 5) summary 정보 업데이트\n",
    "    total = len(finished_props)  # 母수: 종료된 프로포절 수\n",
    "    count_with_disc = len(discussion_props)\n",
    "    percent = (count_with_disc / total * 100.0) if total > 0 else 0.0\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"space\": space,\n",
    "        \"total_closed\": total,\n",
    "        \"with_discussion\": count_with_disc,\n",
    "        \"without_discussion\": max(total - count_with_disc, 0),\n",
    "        \"pct_with_discussion\": round(percent, 2),\n",
    "    })\n",
    "\n",
    "# ---------- 요약 저장 ----------\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"pct_with_discussion\", ascending=False)\n",
    "summary_df.to_csv(\"Target_proposals/summary_with_discussion_by_space.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ 완료!\")\n",
    "print(\" - Target_proposals/summary_with_discussion_by_space.csv\")\n",
    "print(\" - Target_proposals/<space>_with_discussion.csv (per space)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df8e52c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 샘플 10개 댓글 저장 시작...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving comments: 100%|██████████| 10/10 [00:25<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 완료!\n",
      " - 프로포절별 댓글 CSV: Target_proposals/comments/<space>__<proposal_id>__comments.csv\n",
      " - 통합 CSV: Target_proposals/comments/comments_all.csv\n",
      " - 통합 JSONL(LLM 친화): Target_proposals/comments/comments_all.jsonl\n",
      " - 스킵 로그(비-디스코스): Target_proposals/comments/skipped_non_discourse.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json, time, random, re, requests\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------- HTTP & 유틸 --------\n",
    "TIMEOUT = 30\n",
    "BASE_SLEEP  = 0.6\n",
    "MAX_RETRIES = 5\n",
    "BACKOFF_BASE = 1.7\n",
    "JITTER = (0.1, 0.35)\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"target-proposals-save-comments/0.1\"})\n",
    "\n",
    "def _sleep():\n",
    "    time.sleep(BASE_SLEEP + random.uniform(*JITTER))\n",
    "\n",
    "def fetch_url(url: str) -> requests.Response:\n",
    "    retries = 0\n",
    "    while True:\n",
    "        _sleep()\n",
    "        try:\n",
    "            r = session.get(url, timeout=TIMEOUT)\n",
    "        except requests.RequestException:\n",
    "            if retries < MAX_RETRIES:\n",
    "                delay = (BACKOFF_BASE ** retries) + random.uniform(*JITTER)\n",
    "                time.sleep(delay); retries += 1\n",
    "                continue\n",
    "            raise\n",
    "        if r.status_code == 200:\n",
    "            return r\n",
    "        if r.status_code in (429, 502, 503, 504) and retries < MAX_RETRIES:\n",
    "            ra = r.headers.get(\"Retry-After\")\n",
    "            delay = float(ra) if (ra and ra.isdigit()) else (BACKOFF_BASE ** retries)\n",
    "            time.sleep(delay + random.uniform(*JITTER)); retries += 1\n",
    "            continue\n",
    "        return r\n",
    "\n",
    "def is_discourse_thread(url: str) -> bool:\n",
    "    try:\n",
    "        return url.startswith(\"http\") and \"/t/\" in urlparse(url).path.lower()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def to_ts(iso: str) -> int:\n",
    "    try:\n",
    "        return int(datetime.fromisoformat(iso.replace(\"Z\",\"+00:00\")).timestamp())\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def fetch_discourse_thread(url: str, max_pages: int = 10):\n",
    "    base = url.split(\"?\")[0].rstrip(\"/\")\n",
    "    if not base.endswith(\".json\"):\n",
    "        base = base + \".json\"\n",
    "    posts, header = [], {}\n",
    "    for page in range(1, max_pages + 1):\n",
    "        u = base if page == 1 else base.replace(\".json\", f\".json?page={page}\")\n",
    "        rr = fetch_url(u)\n",
    "        if rr.status_code != 200:\n",
    "            break\n",
    "        j = rr.json()\n",
    "        if page == 1:\n",
    "            header = {\n",
    "                \"title\": j.get(\"title\"),\n",
    "                \"slug\": j.get(\"slug\"),\n",
    "                \"created_at\": j.get(\"created_at\"),\n",
    "                \"posts_count\": j.get(\"posts_count\"),\n",
    "                \"tags\": j.get(\"tags\"),\n",
    "                \"url\": url,\n",
    "            }\n",
    "        chunk = j.get(\"post_stream\", {}).get(\"posts\", [])\n",
    "        if not chunk:\n",
    "            break\n",
    "        for p in chunk:\n",
    "            posts.append({\n",
    "                \"id\": p.get(\"id\"),\n",
    "                \"username\": p.get(\"username\"),\n",
    "                \"user_id\": p.get(\"user_id\"),\n",
    "                \"created_at\": p.get(\"created_at\"),\n",
    "                \"updated_at\": p.get(\"updated_at\"),\n",
    "                \"raw\": p.get(\"raw\"),\n",
    "                \"cooked\": p.get(\"cooked\"),\n",
    "                \"post_number\": p.get(\"post_number\"),\n",
    "                \"reply_to_post_number\": p.get(\"reply_to_post_number\"),\n",
    "            })\n",
    "    return {\"thread\": header, \"posts\": posts}\n",
    "\n",
    "# -------- 입력 로드 & 샘플링 --------\n",
    "os.makedirs(\"Target_proposals\", exist_ok=True)\n",
    "comments_dir = \"Target_proposals/comments\"\n",
    "os.makedirs(comments_dir, exist_ok=True)\n",
    "\n",
    "files = sorted(glob.glob(\"Target_proposals/*_with_discussion.csv\"))\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"Target_proposals/*_with_discussion.csv 가 없습니다. 먼저 생성 코드를 실행하세요.\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "        needed = {\"space\",\"id\",\"title\",\"author\",\"discussion\",\"start\",\"end\",\"end_iso\",\"state\"}\n",
    "        if needed.issubset(df.columns):\n",
    "            dfs.append(df)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"읽을 수 있는 with_discussion CSV가 없습니다.\")\n",
    "\n",
    "all_df = pd.concat(dfs, ignore_index=True)\n",
    "if len(all_df) == 0:\n",
    "    raise RuntimeError(\"with_discussion 행이 비어 있습니다.\")\n",
    "\n",
    "sample_n = min(10, len(all_df))\n",
    "sample_df = all_df.sample(n=sample_n, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# -------- 저장 준비: 통합 아웃풋 --------\n",
    "combined_csv_path = os.path.join(comments_dir, \"comments_all.csv\")\n",
    "combined_jsonl_path = os.path.join(comments_dir, \"comments_all.jsonl\")\n",
    "skip_log_path = os.path.join(comments_dir, \"skipped_non_discourse.csv\")\n",
    "\n",
    "# 통합 파일 초기화\n",
    "pd.DataFrame(columns=[\n",
    "    \"space\",\"proposal_id\",\"proposal_title\",\"discussion_url\",\n",
    "    \"post_id\",\"post_number\",\"reply_to_post_number\",\n",
    "    \"author_username\",\"created_at\",\"created_ts\",\"text_raw\",\"text_html\"\n",
    "]).to_csv(combined_csv_path, index=False)\n",
    "open(combined_jsonl_path, \"w\", encoding=\"utf-8\").close()\n",
    "pd.DataFrame(columns=[\n",
    "    \"space\",\"proposal_id\",\"proposal_title\",\"discussion_url\",\"reason\"\n",
    "]).to_csv(skip_log_path, index=False)\n",
    "\n",
    "print(f\"📝 샘플 {sample_n}개 댓글 저장 시작...\\n\")\n",
    "\n",
    "combined_rows = []\n",
    "skipped_rows = []\n",
    "\n",
    "for i in tqdm(range(sample_n), desc=\"Saving comments\"):\n",
    "    row = sample_df.loc[i]\n",
    "    url = str(row[\"discussion\"]).strip()\n",
    "    space = row[\"space\"]; pid = row[\"id\"]; title = row[\"title\"]\n",
    "    end_ts = int(row.get(\"end\", 0)) if pd.notna(row.get(\"end\", 0)) else 0\n",
    "\n",
    "    if not is_discourse_thread(url):\n",
    "        skipped_rows.append({\n",
    "            \"space\": space, \"proposal_id\": pid, \"proposal_title\": title,\n",
    "            \"discussion_url\": url, \"reason\": \"non-discourse (no structured comments)\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    data = fetch_discourse_thread(url, max_pages=10)\n",
    "    posts = data.get(\"posts\", [])\n",
    "    # 프로포절 종료 이전 댓글만\n",
    "    if end_ts:\n",
    "        posts = [p for p in posts if p.get(\"created_at\") and to_ts(p[\"created_at\"]) <= end_ts]\n",
    "\n",
    "    # ---- 프로포절별 CSV 저장 ----\n",
    "    per_path = os.path.join(comments_dir, f\"{space}__{pid}__comments.csv\")\n",
    "    per_df = pd.DataFrame([{\n",
    "        \"space\": space,\n",
    "        \"proposal_id\": pid,\n",
    "        \"proposal_title\": title,\n",
    "        \"discussion_url\": url,\n",
    "        \"post_id\": p.get(\"id\"),\n",
    "        \"post_number\": p.get(\"post_number\"),\n",
    "        \"reply_to_post_number\": p.get(\"reply_to_post_number\"),\n",
    "        \"author_username\": p.get(\"username\"),\n",
    "        \"created_at\": p.get(\"created_at\"),\n",
    "        \"created_ts\": to_ts(p.get(\"created_at\") or \"\"),\n",
    "        \"text_raw\": p.get(\"raw\"),\n",
    "        \"text_html\": p.get(\"cooked\"),\n",
    "    } for p in posts])\n",
    "    per_df.to_csv(per_path, index=False)\n",
    "\n",
    "    # ---- 통합 CSV/JSONL에 추가 ----\n",
    "    if len(posts):\n",
    "        combined_rows.extend(per_df.to_dict(orient=\"records\"))\n",
    "        with open(combined_jsonl_path, \"a\", encoding=\"utf-8\") as wf:\n",
    "            for p in posts:\n",
    "                record = {\n",
    "                    \"text\": p.get(\"raw\") or p.get(\"cooked\") or \"\",\n",
    "                    \"meta\": {\n",
    "                        \"space\": space,\n",
    "                        \"proposal_id\": pid,\n",
    "                        \"proposal_title\": title,\n",
    "                        \"discussion_url\": url,\n",
    "                        \"post_id\": p.get(\"id\"),\n",
    "                        \"post_number\": p.get(\"post_number\"),\n",
    "                        \"reply_to_post_number\": p.get(\"reply_to_post_number\"),\n",
    "                        \"author_username\": p.get(\"username\"),\n",
    "                        \"created_at\": p.get(\"created_at\"),\n",
    "                        \"created_ts\": to_ts(p.get(\"created_at\") or \"\"),\n",
    "                        \"text_raw\": p.get(\"raw\"),\n",
    "                        \"text_html\": p.get(\"cooked\"),\n",
    "                    }\n",
    "                }\n",
    "                wf.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 통합 CSV 쓰기\n",
    "if combined_rows:\n",
    "    pd.DataFrame(combined_rows).to_csv(combined_csv_path, mode=\"w\", index=False)\n",
    "\n",
    "# 스킵 로그 쓰기\n",
    "if skipped_rows:\n",
    "    pd.DataFrame(skipped_rows).to_csv(skip_log_path, mode=\"w\", index=False)\n",
    "\n",
    "print(\"\\n✅ 완료!\")\n",
    "print(f\" - 프로포절별 댓글 CSV: Target_proposals/comments/<space>__<proposal_id>__comments.csv\")\n",
    "print(f\" - 통합 CSV: {combined_csv_path}\")\n",
    "print(f\" - 통합 JSONL(LLM 친화): {combined_jsonl_path}\")\n",
    "print(f\" - 스킵 로그(비-디스코스): {skip_log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
